{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search engine\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation: we set an initial URL in accordance with our theme, a maximum number of links to save and a maximum number of links to download the contents of. This way, if the links we get do not want to be crawled, we do not need to go back and save more links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Chocolate'\n",
    "max_links = 50     # max nb of links to crawl\n",
    "max_cont = 20      # max nb of links to get content of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This method return at most max_l links, starting from an initial url and getting its children links, \n",
    "their children links and so on in a breadth-first fashion.\n",
    "\n",
    "Returns:\n",
    "    list\n",
    "        a list of strings that are the links\n",
    "\"\"\"\n",
    "\n",
    "def crawl_for_links(Links=[], pointer=0, max_l=max_links):\n",
    "    \n",
    "    url = Links[pointer]\n",
    "    html_page = urllib.request.urlopen(url)   # Open url on internet\n",
    "    soup = bs(html_page, 'lxml')              # Open contents of url\n",
    "    \n",
    "    counter = len(Links)\n",
    "\n",
    "    # Use regex to extract all links from url, stop if we reach maximum\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^http://\")}):\n",
    "        if(counter < max_l)&(link not in Links):\n",
    "            Links.append(link.get('href'))\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # If we stll do not have enough links: repeat the process with the next url from the list\n",
    "    if counter < max_l :\n",
    "        Links = crawl_for_links(Links, pointer+1, max_l - counter)\n",
    "        \n",
    "\n",
    "    return Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a7464bdbf7454b2ab532e1a6c882cd68\n"
     ]
    }
   ],
   "source": [
    "hash_object = hashlib.md5(b'https://en.wikipedia.org/wiki/Chocolate')\n",
    "print(hash_object.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfunction(url): \n",
    "    hash_object = hashlib.md5(url.encode('utf-8')).hexdigest()\n",
    "    return hash_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a7464bdbf7454b2ab532e1a6c882cd68'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashfunction('https://en.wikipedia.org/wiki/Chocolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_website_locally (url): \n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    filename = hashfunction(url)\n",
    "    open('/data/' + filename + '.txt', 'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_website_locally('https://en.wikipedia.org/wiki/Chocolate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the content of the links. "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
